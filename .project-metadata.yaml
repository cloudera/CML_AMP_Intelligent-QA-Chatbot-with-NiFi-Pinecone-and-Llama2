name: CDF to CML LLama2 Chatbot
description: |
  Host internal open source Llama2 LLM in the form of UI and API endpoint with semantic search from custom knowledge base generated with CDF.

author: Cloudera Inc.
specification_version: 1.0
prototype_version: 1.0
date: "2023-10-02"

runtimes:
  - editor: Workbench
    kernel: Python 3.9
    edition: Nvidia GPU

tasks:
  - type: run_session
    name: Validate GPU Availibility
    script: 0_verify_deps/check_gpu_resources.py
    short_summary: Check for GPU availibility. 
    long_summary: Check GPUs are enabled on this workspace and are currently schedulable.
    kernel: python3
    cpu: 2
    memory: 4
  
  - type: run_session
    name: Validate GPU Capability
    script: 0_verify_deps/check_gpu_capability.py
    short_summary: Check for GPU capability. 
    long_summary: Check GPU device supports the CUDA capabilities required.
    kernel: python3
    cpu: 2
    memory: 8
    gpu: 1

  - type: run_session
    name: Install Dependencies
    script: 1_install_session_deps/download_requirements.py
    short_summary: Install Dependencies
    kernel: python3
    cpu: 2
    memory: 8
    
  - type: create_job
    name: Download Models
    entity_label: download_data_and_models
    script: 2_job-download-models/download_models.py
    arguments: None
    short_summary: Create job to download pre-trained models. 
    long_summary: Create job to download open source pre-trained models required by the application. All models are downloaded to a local directory. 
    cpu: 1
    memory: 4
    environment:
      TASK_TYPE: CREATE/RUN_JOB

  - type: run_job
    entity_label: download_data_and_models
    short_summary: Run job to download pre-trained models.

  - type: create_job
    name: Populate Vector DB with documents embeddings
    entity_label: vectordb_insert
    script: 3_job-populate-vectordb/vectordb_insert.py
    arguments: None
    short_summary: Create job to populate Vector Database with document embeddings. 
    long_summary: Create job to launch Milvus Vector Database locally and insert embeddings for documents. Embeddings are generated by the locally running embeddings model.
    cpu: 1
    memory: 4
    environment:
      TASK_TYPE: CREATE/RUN_JOB

  - type: run_job
    entity_label: vectordb_insert
    short_summary: Populate Vector DB with documents embeddings
  
  - type: start_application
    name: CML Llama2 Chatbot Interface
    subdomain: cml-llama2-api
    script: 4_app/frontend_app.py
    short_summary: Start CML Llama2 frontend application
    long_summary: Start CML Llama2 frontend application. Ensure available GPUs for best performance. Remember to enable unauthenticated app access for external facing API calls.
    cpu: 2
    memory: 16
    gpu: 1
    environment_variables:
      TASK_TYPE: START_APPLICATION


  - type: create_application
    name: CML Llama2 Chatbot API
    subdomain: cml-llama2-api
    script: 4_app/frontend_app.py
    short_summary: Start CML Llama2 frontend application
    long_summary: Start CML Llama2 frontend application. Ensure available GPUs for best performance. Remember to enable unauthenticated app access for external facing API calls.
    cpu: 2
    memory: 16
    gpu: 1
    environment_variables:
      TASK_TYPE: START_APPLICATION
