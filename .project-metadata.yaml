name: CDF to CML LLama2 Chatbot
description: |
  Host internal open source Llama2 LLM in the form of UI and API endpoint with semantic search from custom knowledge base generated with CDF.

author: Cloudera Inc.
specification_version: 1.0
prototype_version: 1.0
date: "2023-10-02"

runtimes:
  - editor: Workbench
    kernel: Python 3.9
    edition: Nvidia GPU

tasks:
  - type: run_session
    name: Validate GPU Availibility
    script: 0_verify_deps/check_gpu_resources.py
    short_summary: Check for GPU availibility. 
    long_summary: Check GPUs are enabled on this workspace and are currently schedulable.
    kernel: python3
    cpu: 2
    memory: 4

  - type: run_session
    name: Validate GPU Capability
    script: 0_verify_deps/check_gpu_capability.py
    short_summary: Check for GPU capability. 
    long_summary: Check GPUs are capable on this workspace and meet project requirements.
    kernel: python3
    cpu: 2
    memory: 4
    gpu: 1

  - type: run_session
    name: Install Dependencies
    script: 1_install_session_deps/download_requirements.py
    short_summary: Install Dependencies
    kernel: python3
    cpu: 4
    memory: 16
    
  - type: create_job
    name: Download Models
    entity_label: download_data_and_models
    script: 2_job-download-models/download_models.py
    arguments: None
    short_summary: Create job to download pre-trained models. 
    long_summary: Create job to download open source pre-trained models required by the application. All models are downloaded to a local directory. 
    cpu: 1
    memory: 4
    environment:
      TASK_TYPE: CREATE/RUN_JOB

  - type: run_job
    entity_label: download_data_and_models
    short_summary: Run job to download pre-trained models.

  - type: create_job
    name: Populate Vector DB with documents embeddings
    entity_label: vectordb_insert
    script: 3_job-populate-vectordb/vectordb_insert.py
    arguments: None
    short_summary: Create job to populate Vector Database with document embeddings. 
    long_summary: Create job to launch Milvus Vector Database locally and insert embeddings for documents. Embeddings are generated by the locally running embeddings model.
    cpu: 1
    memory: 4
    environment:
      TASK_TYPE: CREATE/RUN_JOB

  - type: run_job
    entity_label: vectordb_insert
    short_summary: Populate Vector DB with documents embeddings
  
  - type: start_application
    name: CML Llama2 Chatbot API
    subdomain: cml-llama2-api
    script: 4_app/api_app.py
    short_summary: Create CML Llama2 API application
    long_summary: Create CML Llama2 API application. To run this, you will shut down the interface version of the application and start this one. Ensure available GPUs for best performance. Remember to enable unauthenticated app access for external facing API calls.
    cpu: 2
    memory: 16
    gpu: 1
    environment_variables:
      TASK_TYPE: START_APPLICATION

  - type: start_application
    name: CML Llama2 Chatbot Interface
    subdomain: cml-llama2-ui
    script: 4_app/frontend_app.py
    short_summary: Create and start CML Llama2 frontend application
    long_summary: Create and start CML Llama2 frontend application. Ensure available GPUs for best performance. Remember to enable unauthenticated app access for external access to the UI.
    cpu: 2
    memory: 16
    gpu: 1
    environment_variables:
      TASK_TYPE: START_APPLICATION
